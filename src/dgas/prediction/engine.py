"""Prediction engine for scheduled signal generation."""

from __future__ import annotations

from dataclasses import dataclass, field
from datetime import datetime, timezone
from decimal import Decimal
from enum import Enum
from typing import Any, Dict, List, Optional, Sequence

from ..calculations.multi_timeframe import (
    MultiTimeframeAnalysis,
    MultiTimeframeCoordinator,
    TimeframeData,
    ConfluenceZone,
)
from ..calculations.states import TrendDirection
from ..data.models import IntervalData


class SignalType(Enum):
    """Type of trading signal."""
    LONG = "LONG"
    SHORT = "SHORT"
    EXIT_LONG = "EXIT_LONG"
    EXIT_SHORT = "EXIT_SHORT"


@dataclass(frozen=True)
class GeneratedSignal:
    """
    A trading signal generated by the prediction system.

    This dataclass represents an actionable trading signal with all necessary
    context for execution and later evaluation.
    """
    # Identification
    symbol: str
    signal_timestamp: datetime
    signal_type: SignalType

    # Entry details
    entry_price: Decimal
    stop_loss: Decimal
    target_price: Decimal

    # Confidence & strength (0.0-1.0)
    confidence: float
    signal_strength: float
    timeframe_alignment: float

    # Risk metrics
    risk_reward_ratio: float

    # Context
    htf_trend: TrendDirection
    trading_tf_state: str  # Market state at trading timeframe
    confluence_zones_count: int
    pattern_context: Dict[str, Any]  # Triggering patterns and indicators

    # Multi-timeframe details
    htf_timeframe: str
    trading_timeframe: str

    # Optional notification tracking (filled by NotificationRouter)
    notification_sent: bool = False
    notification_channels: Optional[List[str]] = None
    notification_timestamp: Optional[datetime] = None


class SignalGenerator:
    """
    Generate actionable trading signals from multi-timeframe analysis.

    This class wraps the MultiTimeframeCoordinator and applies entry rules,
    calculates levels (entry/stop/target), and assigns confidence scores.
    """

    def __init__(
        self,
        coordinator: MultiTimeframeCoordinator,
        min_alignment_score: float = 0.6,
        min_signal_strength: float = 0.5,
        stop_loss_atr_multiplier: float = 1.5,
        target_rr_ratio: float = 2.0,
    ):
        """
        Initialize signal generator.

        Args:
            coordinator: Multi-timeframe coordinator for analysis
            min_alignment_score: Minimum timeframe alignment to generate signals
            min_signal_strength: Minimum signal strength threshold
            stop_loss_atr_multiplier: ATR multiplier for stop loss distance
            target_rr_ratio: Risk/reward ratio for target calculation
        """
        self.coordinator = coordinator
        self.min_alignment_score = min_alignment_score
        self.min_signal_strength = min_signal_strength
        self.stop_loss_atr_multiplier = stop_loss_atr_multiplier
        self.target_rr_ratio = target_rr_ratio

    def generate_signals(
        self,
        symbol: str,
        htf_data: TimeframeData,
        trading_tf_data: TimeframeData,
        ltf_data: Optional[TimeframeData] = None,
    ) -> List[GeneratedSignal]:
        """
        Generate trading signals for a symbol using multi-timeframe analysis.

        Args:
            symbol: Market symbol
            htf_data: Higher timeframe data
            trading_tf_data: Trading timeframe data
            ltf_data: Optional lower timeframe data for precision

        Returns:
            List of generated signals (typically 0-2 per symbol)
        """
        # Run multi-timeframe analysis
        analysis = self.coordinator.analyze(htf_data, trading_tf_data, ltf_data)

        # Check if analysis meets minimum criteria
        if not self._meets_minimum_criteria(analysis):
            return []

        # Determine signal type based on entry rules
        signal_type = self._apply_entry_rules(analysis)
        if signal_type is None:
            return []

        # Calculate entry, stop, and target levels
        entry_price, stop_loss, target_price = self._calculate_levels(
            signal_type, analysis, trading_tf_data
        )

        # Calculate confidence score
        confidence = self._calculate_confidence(analysis)

        # Calculate risk/reward ratio
        if signal_type in [SignalType.LONG, SignalType.SHORT]:
            risk = abs(entry_price - stop_loss)
            reward = abs(target_price - entry_price)
            rr_ratio = float(reward / risk) if risk > 0 else 0.0
        else:
            rr_ratio = 0.0

        # Build pattern context
        pattern_context = self._build_pattern_context(analysis)

        # Create signal
        signal = GeneratedSignal(
            symbol=symbol,
            signal_timestamp=analysis.timestamp,
            signal_type=signal_type,
            entry_price=entry_price,
            stop_loss=stop_loss,
            target_price=target_price,
            confidence=confidence,
            signal_strength=float(analysis.signal_strength),
            timeframe_alignment=float(analysis.alignment.alignment_score),
            risk_reward_ratio=rr_ratio,
            htf_trend=analysis.htf_trend,
            trading_tf_state=analysis.alignment.trading_tf_state.value,
            confluence_zones_count=len(analysis.confluence_zones),
            pattern_context=pattern_context,
            htf_timeframe=analysis.htf_timeframe,
            trading_timeframe=analysis.trading_timeframe,
        )

        return [signal]

    def _meets_minimum_criteria(self, analysis: MultiTimeframeAnalysis) -> bool:
        """
        Check if analysis meets minimum criteria for signal generation.

        Args:
            analysis: Multi-timeframe analysis

        Returns:
            True if criteria met
        """
        # Check alignment score
        if float(analysis.alignment.alignment_score) < self.min_alignment_score:
            return False

        # Check signal strength
        if float(analysis.signal_strength) < self.min_signal_strength:
            return False

        # Check that trade is permitted by HTF
        if not analysis.alignment.trade_permitted:
            return False

        return True

    def _apply_entry_rules(
        self,
        analysis: MultiTimeframeAnalysis,
    ) -> Optional[SignalType]:
        """
        Determine signal type based on entry rules.

        Entry Rules (Multi-Timeframe Strategy):
        - LONG: HTF trend UP + trading TF alignment ≥ threshold + price near support
        - SHORT: HTF trend DOWN + trading TF alignment ≥ threshold + price near resistance
        - EXIT: Alignment breaks below threshold OR risk level high

        Args:
            analysis: Multi-timeframe analysis

        Returns:
            Signal type or None if no signal
        """
        # Check for exit conditions first
        if analysis.recommended_action == "reduce" or analysis.risk_level == "high":
            # Determine which exit based on current HTF trend (exiting against trend)
            if analysis.htf_trend == TrendDirection.UP:
                return SignalType.EXIT_SHORT  # Exit if we were short
            elif analysis.htf_trend == TrendDirection.DOWN:
                return SignalType.EXIT_LONG  # Exit if we were long
            return None

        # Check for entry conditions
        if analysis.recommended_action == "long" and analysis.htf_trend == TrendDirection.UP:
            # Additional validation: check for support confluence
            if analysis.confluence_zones:
                support_zones = [z for z in analysis.confluence_zones if z.zone_type == "support"]
                if support_zones:
                    return SignalType.LONG

        elif analysis.recommended_action == "short" and analysis.htf_trend == TrendDirection.DOWN:
            # Additional validation: check for resistance confluence
            if analysis.confluence_zones:
                resistance_zones = [z for z in analysis.confluence_zones if z.zone_type == "resistance"]
                if resistance_zones:
                    return SignalType.SHORT

        # No signal if recommended action is "wait"
        return None

    def _calculate_levels(
        self,
        signal_type: SignalType,
        analysis: MultiTimeframeAnalysis,
        trading_tf_data: TimeframeData,
    ) -> tuple[Decimal, Decimal, Decimal]:
        """
        Calculate entry, stop loss, and target price levels.

        Logic:
        - Entry: Current PLdot value at trading TF
        - Stop: Entry +/- (ATR * multiplier) based on direction
        - Target: Entry +/- (stop_distance * RR_ratio) based on direction

        For confluence zones: adjust entry to nearest zone level

        Args:
            signal_type: Type of signal
            analysis: Multi-timeframe analysis
            trading_tf_data: Trading timeframe data

        Returns:
            Tuple of (entry_price, stop_loss, target_price)
        """
        # Get current trading TF PLdot as baseline entry
        if not trading_tf_data.pldot_series:
            raise ValueError("No PLdot data available for entry calculation")

        current_pldot = trading_tf_data.pldot_series[-1]
        entry_price = current_pldot.value

        # Adjust entry to nearest confluence zone if available
        if analysis.confluence_zones:
            if signal_type == SignalType.LONG:
                # For long, look for nearest support below current price
                support_zones = [
                    z for z in analysis.confluence_zones
                    if z.zone_type == "support" and z.level <= entry_price
                ]
                if support_zones:
                    # Use strongest support zone
                    strongest = max(support_zones, key=lambda z: z.strength)
                    entry_price = strongest.level

            elif signal_type == SignalType.SHORT:
                # For short, look for nearest resistance above current price
                resistance_zones = [
                    z for z in analysis.confluence_zones
                    if z.zone_type == "resistance" and z.level >= entry_price
                ]
                if resistance_zones:
                    # Use strongest resistance zone
                    strongest = max(resistance_zones, key=lambda z: z.strength)
                    entry_price = strongest.level

        # Calculate stop loss based on envelope width (proxy for ATR)
        if trading_tf_data.envelope_series:
            latest_envelope = trading_tf_data.envelope_series[-1]
            atr_proxy = latest_envelope.width
        else:
            # Fallback: use 2% of entry price
            atr_proxy = entry_price * Decimal("0.02")

        stop_distance = atr_proxy * Decimal(str(self.stop_loss_atr_multiplier))

        # Calculate stop and target based on signal direction
        if signal_type == SignalType.LONG:
            stop_loss = entry_price - stop_distance
            target_price = entry_price + (stop_distance * Decimal(str(self.target_rr_ratio)))

        elif signal_type == SignalType.SHORT:
            stop_loss = entry_price + stop_distance
            target_price = entry_price - (stop_distance * Decimal(str(self.target_rr_ratio)))

        elif signal_type in [SignalType.EXIT_LONG, SignalType.EXIT_SHORT]:
            # For exits, entry is current price, stop/target are N/A but set to entry
            stop_loss = entry_price
            target_price = entry_price

        else:
            raise ValueError(f"Unexpected signal type: {signal_type}")

        return entry_price, stop_loss, target_price

    def _calculate_confidence(self, analysis: MultiTimeframeAnalysis) -> float:
        """
        Calculate signal confidence score (0.0-1.0).

        Factors:
        - Timeframe alignment strength (30%)
        - Pattern confluence (20%)
        - HTF trend strength (25%)
        - Confluence zone count (15%)
        - Signal strength from analysis (10%)

        Args:
            analysis: Multi-timeframe analysis

        Returns:
            Confidence score between 0.0 and 1.0
        """
        # Component scores (0.0-1.0)
        alignment_component = float(analysis.alignment.alignment_score) * 0.30

        pattern_component = 0.20 if analysis.pattern_confluence else 0.10

        htf_strength_component = float(analysis.htf_trend_strength) * 0.25

        # Confluence zones: normalize by max expected (e.g., 5 zones = full score)
        max_zones = 5
        zones_count = min(len(analysis.confluence_zones), max_zones)
        zones_component = (zones_count / max_zones) * 0.15

        signal_strength_component = float(analysis.signal_strength) * 0.10

        # Sum components
        confidence = (
            alignment_component +
            pattern_component +
            htf_strength_component +
            zones_component +
            signal_strength_component
        )

        # Clamp to [0.0, 1.0]
        return max(0.0, min(1.0, confidence))

    def _build_pattern_context(self, analysis: MultiTimeframeAnalysis) -> Dict[str, Any]:
        """
        Build pattern context dictionary for signal metadata.

        Args:
            analysis: Multi-timeframe analysis

        Returns:
            Dictionary with pattern and indicator context
        """
        return {
            "htf_patterns": [
                {
                    "type": p.pattern_type.value,
                    "direction": p.direction,
                    "strength": p.strength,
                }
                for p in analysis.htf_patterns
            ],
            "trading_tf_patterns": [
                {
                    "type": p.pattern_type.value,
                    "direction": p.direction,
                    "strength": p.strength,
                }
                for p in analysis.trading_tf_patterns
            ],
            "alignment_type": analysis.alignment.alignment_type,
            "risk_level": analysis.risk_level,
            "recommended_action": analysis.recommended_action,
            "htf_pldot": float(analysis.pldot_overlay.htf_pldot_value),
            "trading_pldot": float(analysis.pldot_overlay.ltf_pldot_value),
            "pldot_distance_pct": float(analysis.pldot_overlay.distance_percent),
        }


class SignalAggregator:
    """
    Aggregate, filter, and rank signals for notification.

    Responsibilities:
    - Remove duplicate signals (same symbol + direction within time window)
    - Apply user-defined filters (min confidence, enabled patterns, etc.)
    - Rank signals by composite score for priority notification
    """

    def __init__(
        self,
        duplicate_window_minutes: int = 60,
    ):
        """
        Initialize signal aggregator.

        Args:
            duplicate_window_minutes: Time window for duplicate detection
        """
        self.duplicate_window_minutes = duplicate_window_minutes

    def aggregate_signals(
        self,
        signals: List[GeneratedSignal],
        min_confidence: Optional[float] = None,
        min_alignment: Optional[float] = None,
        enabled_patterns: Optional[List[str]] = None,
        max_signals: Optional[int] = None,
    ) -> List[GeneratedSignal]:
        """
        Filter, de-duplicate, and rank signals.

        Args:
            signals: Input signals
            min_confidence: Minimum confidence filter
            min_alignment: Minimum timeframe alignment filter
            enabled_patterns: List of enabled pattern types (None = all)
            max_signals: Maximum signals to return

        Returns:
            Filtered and ranked signals
        """
        if not signals:
            return []

        # Step 1: Apply filters
        filtered = self._apply_filters(
            signals, min_confidence, min_alignment, enabled_patterns
        )

        if not filtered:
            return []

        # Step 2: Remove duplicates
        deduplicated = self._detect_duplicates(filtered)

        # Step 3: Rank by composite score
        ranked = self._rank_signals(deduplicated)

        # Step 4: Limit to max_signals if specified
        if max_signals is not None:
            ranked = ranked[:max_signals]

        return ranked

    def _apply_filters(
        self,
        signals: List[GeneratedSignal],
        min_confidence: Optional[float],
        min_alignment: Optional[float],
        enabled_patterns: Optional[List[str]],
    ) -> List[GeneratedSignal]:
        """Apply user-defined filters to signals."""
        filtered = signals

        # Filter by minimum confidence
        if min_confidence is not None:
            filtered = [s for s in filtered if s.confidence >= min_confidence]

        # Filter by minimum alignment
        if min_alignment is not None:
            filtered = [s for s in filtered if s.timeframe_alignment >= min_alignment]

        # Filter by enabled patterns
        if enabled_patterns is not None:
            # Check if signal has any of the enabled patterns
            filtered = [
                s for s in filtered
                if self._has_enabled_pattern(s, enabled_patterns)
            ]

        return filtered

    def _has_enabled_pattern(
        self, signal: GeneratedSignal, enabled_patterns: List[str]
    ) -> bool:
        """Check if signal contains any enabled patterns."""
        signal_patterns = []

        # Extract pattern types from context
        if "htf_patterns" in signal.pattern_context:
            signal_patterns.extend([p["type"] for p in signal.pattern_context["htf_patterns"]])
        if "trading_tf_patterns" in signal.pattern_context:
            signal_patterns.extend([p["type"] for p in signal.pattern_context["trading_tf_patterns"]])

        # Check if any signal pattern is in enabled list
        return any(p in enabled_patterns for p in signal_patterns) if signal_patterns else True

    def _detect_duplicates(
        self, signals: List[GeneratedSignal]
    ) -> List[GeneratedSignal]:
        """
        Remove duplicate signals for same symbol + signal type within time window.

        Keep the signal with highest confidence.
        """
        if len(signals) <= 1:
            return signals

        # Group by (symbol, signal_type)
        groups: Dict[tuple[str, SignalType], List[GeneratedSignal]] = {}
        for signal in signals:
            key = (signal.symbol, signal.signal_type)
            if key not in groups:
                groups[key] = []
            groups[key].append(signal)

        # For each group, keep only highest confidence signal within time window
        deduplicated = []
        for group_signals in groups.values():
            if len(group_signals) == 1:
                deduplicated.append(group_signals[0])
            else:
                # Sort by timestamp
                sorted_signals = sorted(group_signals, key=lambda s: s.signal_timestamp)

                # Keep non-overlapping signals
                kept = [sorted_signals[0]]
                for signal in sorted_signals[1:]:
                    last_kept = kept[-1]
                    time_diff_minutes = (
                        signal.signal_timestamp - last_kept.signal_timestamp
                    ).total_seconds() / 60

                    if time_diff_minutes > self.duplicate_window_minutes:
                        # Outside window, keep both
                        kept.append(signal)
                    else:
                        # Within window, keep higher confidence
                        if signal.confidence > last_kept.confidence:
                            kept[-1] = signal

                deduplicated.extend(kept)

        return deduplicated

    def _rank_signals(self, signals: List[GeneratedSignal]) -> List[GeneratedSignal]:
        """
        Rank signals by composite score.

        Score = confidence * signal_strength * timeframe_alignment
        """
        def composite_score(signal: GeneratedSignal) -> float:
            return signal.confidence * signal.signal_strength * signal.timeframe_alignment

        return sorted(signals, key=composite_score, reverse=True)


@dataclass(frozen=True)
class PredictionRunResult:
    """Result of a single prediction cycle execution."""
    run_id: int
    timestamp: datetime
    symbols_requested: int
    symbols_processed: int
    signals_generated: int
    execution_time_ms: int
    errors: List[str]
    status: str  # "SUCCESS", "PARTIAL", "FAILED"

    # Latency breakdown
    data_fetch_ms: Optional[int] = None
    indicator_calc_ms: Optional[int] = None
    signal_generation_ms: Optional[int] = None

    # Generated signals (for notification)
    signals: List[GeneratedSignal] = field(default_factory=list)


class PredictionEngine:
    """
    Orchestrate the full prediction pipeline.

    This class coordinates:
    1. Incremental data refresh from EODHD
    2. Indicator recalculation for updated symbols
    3. Multi-timeframe signal generation
    4. Result persistence

    Usage:
        engine = PredictionEngine(settings, persistence)
        result = engine.execute_prediction_cycle(
            symbols=["AAPL", "MSFT"],
            interval="30min",
            timeframes=["4h", "1h", "30min"]
        )
    """

    def __init__(
        self,
        settings: Any = None,  # Will import Settings type
        persistence: Any = None,  # Will import PredictionPersistence type
        signal_generator: Optional[SignalGenerator] = None,
        lookback_bars: int = 200,
    ):
        """
        Initialize prediction engine.

        Args:
            settings: Settings instance (imported from dgas.settings)
            persistence: PredictionPersistence instance
            signal_generator: Optional SignalGenerator (will create default if None)
            lookback_bars: Number of bars to load for analysis
        """
        if settings is None:
            from ..settings import get_settings
            settings = get_settings()

        if persistence is None:
            from ..prediction.persistence import PredictionPersistence
            persistence = PredictionPersistence(settings)

        self.settings = settings
        self.persistence = persistence
        self.lookback_bars = lookback_bars

        # Create default signal generator if not provided
        if signal_generator is None:
            from ..calculations.multi_timeframe import MultiTimeframeCoordinator
            coordinator = MultiTimeframeCoordinator(
                htf_timeframe="4h",
                trading_timeframe="1h",
            )
            signal_generator = SignalGenerator(coordinator)

        self.signal_generator = signal_generator

    def execute_prediction_cycle(
        self,
        symbols: List[str],
        interval: str,
        timeframes: List[str],
        htf_interval: Optional[str] = None,
        trading_interval: Optional[str] = None,
        persist_results: bool = True,
    ) -> PredictionRunResult:
        """
        Execute full prediction cycle for given symbols.

        Steps:
        1. Refresh market data (incremental update)
        2. Recalculate indicators for symbols with new data
        3. Generate signals via SignalGenerator
        4. Persist signals and run metadata
        5. Return execution results

        Args:
            symbols: List of symbols to analyze
            interval: Primary interval for analysis
            timeframes: List of timeframes for multi-TF analysis
            htf_interval: Optional override for higher timeframe (default: timeframes[0])
            trading_interval: Optional override for trading timeframe (default: timeframes[1] or interval)
            persist_results: Whether to save to database

        Returns:
            PredictionRunResult with execution metadata
        """
        import time
        from datetime import timezone

        start_time = time.time()
        run_timestamp = datetime.now(timezone.utc)
        errors = []
        symbols_processed = 0
        all_signals = []

        # Determine timeframes
        if htf_interval is None:
            htf_interval = timeframes[0] if len(timeframes) > 0 else "4h"
        if trading_interval is None:
            trading_interval = timeframes[1] if len(timeframes) > 1 else interval

        # Step 1: Refresh market data
        data_fetch_start = time.time()
        updated_symbols = self._refresh_market_data(symbols, interval, errors)
        data_fetch_ms = int((time.time() - data_fetch_start) * 1000)

        # Step 2: Recalculate indicators and generate signals
        indicator_calc_start = time.time()
        signal_gen_start = None
        signal_gen_ms = 0

        for symbol in symbols:
            try:
                # Load market data
                intervals_data = self._load_market_data(symbol, interval)
                if not intervals_data:
                    errors.append(f"{symbol}: No market data available")
                    continue

                # Calculate indicators for all required timeframes
                htf_data = None
                trading_data = None

                # Load HTF data if different from primary interval
                if htf_interval != interval:
                    try:
                        htf_intervals = self._load_market_data(symbol, htf_interval)
                        if htf_intervals:
                            htf_data = self._calculate_timeframe_data(
                                htf_intervals, htf_interval, TimeframeType.HIGHER
                            )
                    except Exception as e:
                        errors.append(f"{symbol}: HTF data error - {str(e)}")

                # Load trading TF data
                if trading_interval == interval:
                    trading_data = self._calculate_timeframe_data(
                        intervals_data, trading_interval, TimeframeType.TRADING
                    )
                else:
                    try:
                        trading_intervals = self._load_market_data(symbol, trading_interval)
                        if trading_intervals:
                            trading_data = self._calculate_timeframe_data(
                                trading_intervals, trading_interval, TimeframeType.TRADING
                            )
                    except Exception as e:
                        errors.append(f"{symbol}: Trading TF data error - {str(e)}")

                # Ensure we have both HTF and trading data
                if htf_data is None or trading_data is None:
                    errors.append(f"{symbol}: Missing timeframe data")
                    continue

                # Step 3: Generate signals
                if signal_gen_start is None:
                    signal_gen_start = time.time()

                signals = self.signal_generator.generate_signals(
                    symbol, htf_data, trading_data
                )
                all_signals.extend(signals)
                symbols_processed += 1

            except Exception as e:
                errors.append(f"{symbol}: {str(e)}")

        indicator_calc_ms = int((time.time() - indicator_calc_start) * 1000)
        if signal_gen_start:
            signal_gen_ms = int((time.time() - signal_gen_start) * 1000)

        # Calculate total execution time
        execution_time_ms = int((time.time() - start_time) * 1000)

        # Determine status
        if symbols_processed == 0:
            status = "FAILED"
        elif symbols_processed < len(symbols):
            status = "PARTIAL"
        else:
            status = "SUCCESS"

        # Step 4: Persist results if requested
        run_id = 0
        if persist_results:
            try:
                # Save prediction run
                run_id = self.persistence.save_prediction_run(
                    interval_type=interval,
                    symbols_requested=len(symbols),
                    symbols_processed=symbols_processed,
                    signals_generated=len(all_signals),
                    execution_time_ms=execution_time_ms,
                    status=status,
                    data_fetch_ms=data_fetch_ms,
                    indicator_calc_ms=indicator_calc_ms,
                    signal_generation_ms=signal_gen_ms,
                    errors=errors if errors else None,
                    run_timestamp=run_timestamp,
                )

                # Save generated signals
                if all_signals:
                    signal_dicts = [self._signal_to_dict(s) for s in all_signals]
                    self.persistence.save_generated_signals(run_id, signal_dicts)

            except Exception as e:
                errors.append(f"Persistence error: {str(e)}")
                status = "FAILED"

        # Return result with signals
        return PredictionRunResult(
            run_id=run_id,
            timestamp=run_timestamp,
            symbols_requested=len(symbols),
            symbols_processed=symbols_processed,
            signals_generated=len(all_signals),
            execution_time_ms=execution_time_ms,
            errors=errors,
            status=status,
            data_fetch_ms=data_fetch_ms,
            indicator_calc_ms=indicator_calc_ms,
            signal_generation_ms=signal_gen_ms,
            signals=all_signals,  # Include signal objects for notification
        )

    def _refresh_market_data(
        self,
        symbols: List[str],
        interval: str,
        errors: List[str],
    ) -> List[str]:
        """
        Incrementally refresh market data for symbols.

        Args:
            symbols: Symbols to update
            interval: Interval to update
            errors: List to append errors to

        Returns:
            List of symbols that were successfully updated
        """
        from ..data.ingestion import incremental_update_intraday

        updated = []
        for symbol in symbols:
            try:
                # Perform incremental update (fetches only recent data)
                summary = incremental_update_intraday(
                    symbol,
                    exchange="US",  # Default exchange
                    interval=interval,
                    buffer_days=2,  # 2 days buffer
                )

                if summary.stored > 0 or summary.fetched > 0:
                    updated.append(symbol)

            except Exception as e:
                errors.append(f"{symbol}: Data refresh failed - {str(e)}")

        return updated

    def _load_market_data(
        self,
        symbol: str,
        interval: str,
    ) -> List[IntervalData]:
        """
        Load market data from database.

        Args:
            symbol: Symbol to load
            interval: Interval to load

        Returns:
            List of IntervalData in chronological order
        """
        from ..db import get_connection

        with get_connection() as conn:
            cursor = conn.cursor()

            # Get symbol_id
            cursor.execute(
                "SELECT symbol_id FROM market_symbols WHERE symbol = %s",
                (symbol,)
            )
            result = cursor.fetchone()
            if result is None:
                raise ValueError(f"Symbol {symbol} not found in database")
            symbol_id = result[0]

            # Get recent market data
            cursor.execute(
                """
                SELECT
                    timestamp, open_price, high_price, low_price,
                    close_price, volume
                FROM market_data
                WHERE symbol_id = %s AND interval_type = %s
                ORDER BY timestamp DESC
                LIMIT %s
                """,
                (symbol_id, interval, self.lookback_bars)
            )

            rows = cursor.fetchall()
            if not rows:
                return []

            # Convert to IntervalData (reverse to chronological order)
            intervals = []
            for row in reversed(rows):
                timestamp, open_p, high_p, low_p, close_p, volume = row
                intervals.append(
                    IntervalData(
                        symbol=symbol,
                        interval=interval,
                        timestamp=timestamp,
                        open=Decimal(str(open_p)),
                        high=Decimal(str(high_p)),
                        low=Decimal(str(low_p)),
                        close=Decimal(str(close_p)),
                        volume=int(volume),
                        adjusted_close=Decimal(str(close_p)),
                    )
                )

            return intervals

    def _calculate_timeframe_data(
        self,
        intervals: List[IntervalData],
        timeframe: str,
        classification: Any,  # TimeframeType
    ) -> TimeframeData:
        """
        Calculate all Drummond indicators for a timeframe.

        Args:
            intervals: Market data intervals
            timeframe: Timeframe label (e.g., "4h", "1h")
            classification: TimeframeType classification

        Returns:
            TimeframeData with all indicators calculated
        """
        from ..calculations import (
            EnvelopeCalculator,
            MarketStateClassifier,
            PLDotCalculator,
        )
        from ..calculations.patterns import (
            detect_c_wave,
            detect_congestion_oscillation,
            detect_exhaust,
            detect_pldot_push,
            detect_pldot_refresh,
        )

        # PLdot calculation
        pldot_calc = PLDotCalculator(displacement=1)
        pldot_series = pldot_calc.from_intervals(intervals)

        # Envelope calculation
        envelope_calc = EnvelopeCalculator(
            method="pldot_range",
            period=3,
            multiplier=1.5
        )
        envelope_series = envelope_calc.from_intervals(intervals, pldot_series)

        # Market state classification
        state_classifier = MarketStateClassifier(slope_threshold=0.0001)
        state_series = state_classifier.classify(intervals, pldot_series)

        # Pattern detection
        patterns = []
        patterns.extend(detect_pldot_push(intervals, pldot_series))
        patterns.extend(detect_pldot_refresh(intervals, pldot_series))
        patterns.extend(detect_exhaust(intervals, pldot_series, envelope_series))
        patterns.extend(detect_c_wave(envelope_series))
        patterns.extend(detect_congestion_oscillation(envelope_series))

        return TimeframeData(
            timeframe=timeframe,
            classification=classification,
            pldot_series=pldot_series,
            envelope_series=envelope_series,
            state_series=state_series,
            pattern_events=patterns,
        )

    def _signal_to_dict(self, signal: GeneratedSignal) -> Dict[str, Any]:
        """
        Convert GeneratedSignal to dictionary for persistence.

        Args:
            signal: Generated signal

        Returns:
            Dictionary compatible with save_generated_signals
        """
        return {
            "symbol": signal.symbol,
            "signal_timestamp": signal.signal_timestamp,
            "signal_type": signal.signal_type.value,
            "entry_price": signal.entry_price,
            "stop_loss": signal.stop_loss,
            "target_price": signal.target_price,
            "confidence": signal.confidence,
            "signal_strength": signal.signal_strength,
            "timeframe_alignment": signal.timeframe_alignment,
            "risk_reward_ratio": signal.risk_reward_ratio,
            "htf_trend": signal.htf_trend.value,
            "trading_tf_state": signal.trading_tf_state,
            "confluence_zones_count": signal.confluence_zones_count,
            "pattern_context": signal.pattern_context,
            "notification_sent": signal.notification_sent,
            "notification_channels": signal.notification_channels,
            "notification_timestamp": signal.notification_timestamp,
        }


__all__ = [
    "SignalType",
    "GeneratedSignal",
    "SignalGenerator",
    "SignalAggregator",
    "PredictionEngine",
    "PredictionRunResult",
]
