"""Prediction engine for scheduled signal generation."""

from __future__ import annotations

import logging

logger = logging.getLogger(__name__)

from dataclasses import dataclass, field
from datetime import datetime, timezone
from decimal import Decimal
from enum import Enum
from typing import Any, Dict, List, Optional, Sequence

from ..calculations.multi_timeframe import (
    ConfluenceZone,
    MultiTimeframeAnalysis,
    MultiTimeframeCoordinator,
    TimeframeData,
)
from ..calculations import build_timeframe_data
from ..calculations.patterns import PatternEvent, PatternType
from ..calculations.states import TrendDirection
from ..data.models import IntervalData


class SignalType(Enum):
    """Type of trading signal."""
    LONG = "LONG"
    SHORT = "SHORT"
    EXIT_LONG = "EXIT_LONG"
    EXIT_SHORT = "EXIT_SHORT"


class SignalTier(Enum):
    """
    Signal confidence tier for tiered signal generation.
    
    Tiers represent different levels of signal quality and confidence:
    - HIGH: Full confluence with pattern support, highest probability
    - MEDIUM: Zone-based with good alignment, moderate probability
    - LOW: Strong zone only, lower probability but still actionable
    """
    HIGH = "HIGH"
    MEDIUM = "MEDIUM"
    LOW = "LOW"


@dataclass
class TierThresholds:
    """Threshold configuration for a single signal tier."""
    min_alignment_score: float
    min_signal_strength: float
    min_zone_weight: float
    require_pattern: bool
    position_size_multiplier: float  # Multiplier for position sizing (e.g., 1.0, 0.75, 0.5)


@dataclass
class TieredSignalConfig:
    """
    Configuration for tiered signal generation.
    
    This allows generating signals at different confidence levels,
    each with appropriate thresholds and position sizing.
    """
    # High tier: Full confluence with pattern support
    high_tier: TierThresholds = field(default_factory=lambda: TierThresholds(
        min_alignment_score=0.7,
        min_signal_strength=0.65,
        min_zone_weight=3.0,
        require_pattern=True,
        position_size_multiplier=1.0,
    ))
    
    # Medium tier: Zone-based with good alignment
    medium_tier: TierThresholds = field(default_factory=lambda: TierThresholds(
        min_alignment_score=0.6,
        min_signal_strength=0.5,
        min_zone_weight=2.5,
        require_pattern=False,
        position_size_multiplier=0.75,
    ))
    
    # Low tier: Strong zone only
    low_tier: TierThresholds = field(default_factory=lambda: TierThresholds(
        min_alignment_score=0.5,
        min_signal_strength=0.4,
        min_zone_weight=3.5,  # Requires stronger zone to compensate for lower alignment
        require_pattern=False,
        position_size_multiplier=0.5,
    ))
    
    # Which tiers are enabled
    enabled_tiers: List[SignalTier] = field(default_factory=lambda: [
        SignalTier.HIGH,
        SignalTier.MEDIUM,
        SignalTier.LOW,
    ])

    def get_tier_thresholds(self, tier: SignalTier) -> TierThresholds:
        """Get thresholds for a specific tier."""
        if tier == SignalTier.HIGH:
            return self.high_tier
        elif tier == SignalTier.MEDIUM:
            return self.medium_tier
        elif tier == SignalTier.LOW:
            return self.low_tier
        else:
            raise ValueError(f"Unknown tier: {tier}")


@dataclass(frozen=True)
class GeneratedSignal:
    """
    A trading signal generated by the prediction system.

    This dataclass represents an actionable trading signal with all necessary
    context for execution and later evaluation.
    """
    # Identification
    symbol: str
    signal_timestamp: datetime
    signal_type: SignalType

    # Entry details
    entry_price: Decimal
    stop_loss: Decimal
    target_price: Decimal

    # Confidence & strength (0.0-1.0)
    confidence: float
    signal_strength: float
    timeframe_alignment: float

    # Risk metrics
    risk_reward_ratio: float

    # Context
    htf_trend: TrendDirection
    trading_tf_state: str  # Market state at trading timeframe
    confluence_zones_count: int
    pattern_context: Dict[str, Any]  # Triggering patterns and indicators

    # Multi-timeframe details
    htf_timeframe: str
    trading_timeframe: str

    # Tiered signal support (Priority 4 enhancement)
    tier: Optional[SignalTier] = None  # Signal quality tier (HIGH, MEDIUM, LOW)
    position_size_multiplier: float = 1.0  # Position sizing multiplier based on tier

    # Optional notification tracking (filled by NotificationRouter)
    notification_sent: bool = False
    notification_channels: Optional[List[str]] = None
    notification_timestamp: Optional[datetime] = None


class SignalGenerator:
    """
    Generate actionable trading signals from multi-timeframe analysis.

    This class wraps the MultiTimeframeCoordinator and applies entry rules,
    calculates levels (entry/stop/target), and assigns confidence scores.
    """

    def __init__(
        self,
        coordinator: MultiTimeframeCoordinator,
        min_alignment_score: float = 0.6,
        min_signal_strength: float = 0.5,
        stop_loss_atr_multiplier: float = 1.5,
        target_rr_ratio: float = 2.0,
        min_zone_weight: float = 2.5,
        required_pattern_strength: int = 2,
        tiered_config: Optional[TieredSignalConfig] = None,
    ):
        """
        Initialize signal generator.

        Args:
            coordinator: Multi-timeframe coordinator for analysis
            min_alignment_score: Minimum timeframe alignment to generate signals
            min_signal_strength: Minimum signal strength threshold
            stop_loss_atr_multiplier: ATR multiplier for stop loss distance
            target_rr_ratio: Risk/reward ratio for target calculation
            min_zone_weight: Minimum zone weight for signal generation
            required_pattern_strength: Minimum pattern strength required
            tiered_config: Optional tiered signal configuration for multi-tier generation
        """
        self.coordinator = coordinator
        self.min_alignment_score = min_alignment_score
        self.min_signal_strength = min_signal_strength
        self.stop_loss_atr_multiplier = stop_loss_atr_multiplier
        self.target_rr_ratio = target_rr_ratio
        self.min_zone_weight = min_zone_weight
        self.required_pattern_strength = required_pattern_strength
        self.tiered_config = tiered_config

    def generate_signals(
        self,
        symbol: str,
        htf_data: TimeframeData,
        trading_tf_data: TimeframeData,
        ltf_data: Optional[TimeframeData] = None,
    ) -> List[GeneratedSignal]:
        """
        Generate trading signals for a symbol using multi-timeframe analysis.

        Args:
            symbol: Market symbol
            htf_data: Higher timeframe data
            trading_tf_data: Trading timeframe data
            ltf_data: Optional lower timeframe data for precision

        Returns:
            List of generated signals (typically 0-2 per symbol)
        """
        # Run multi-timeframe analysis
        analysis = self.coordinator.analyze(htf_data, trading_tf_data, ltf_data)

        # Check if analysis meets minimum criteria
        if not self._meets_minimum_criteria(analysis):
            # Log why criteria not met for debugging
            logger.debug(
                f"{symbol}: Criteria not met - "
                f"alignment={float(analysis.alignment.alignment_score):.2f} (min={self.min_alignment_score}), "
                f"strength={float(analysis.signal_strength):.2f} (min={self.min_signal_strength}), "
                f"trade_permitted={analysis.alignment.trade_permitted}, "
                f"zones={len(analysis.confluence_zones)}, "
                f"top_zone_weight={float(analysis.confluence_zones[0].weighted_strength) if analysis.confluence_zones else 0:.2f} (min={self.min_zone_weight})"
            )
            return []

        direction = self._determine_direction(analysis)
        if direction is None:
            logger.debug(f"{symbol}: No direction determined - recommended_action={analysis.recommended_action}, htf_trend={analysis.htf_trend}")
            return []

        signal_type = self._map_direction_to_signal(direction, analysis)
        if signal_type is None:
            logger.debug(f"{symbol}: No signal type mapped - direction={direction}, recommended_action={analysis.recommended_action}")
            return []

        is_exit_signal = signal_type in (SignalType.EXIT_LONG, SignalType.EXIT_SHORT)

        zone: Optional[ConfluenceZone] = None
        if not is_exit_signal:
            if not self._has_supporting_pattern(analysis, direction):
                logger.debug(f"{symbol}: No supporting pattern found - direction={direction}, required_strength={self.required_pattern_strength}")
                return []
            zone = self._select_zone(analysis, direction)
            if zone is None:
                logger.debug(f"{symbol}: No zone selected - direction={direction}, min_weight={self.min_zone_weight}")
                return []

        # Calculate entry, stop, and target levels
        entry_price, stop_loss, target_price = self._calculate_levels(
            signal_type, analysis, trading_tf_data, zone
        )

        # Calculate confidence score
        confidence = self._calculate_confidence(analysis)

        # Calculate risk/reward ratio
        if signal_type in [SignalType.LONG, SignalType.SHORT]:
            risk = abs(entry_price - stop_loss)
            reward = abs(target_price - entry_price)
            rr_ratio = float(reward / risk) if risk > 0 else 0.0
        else:
            rr_ratio = 0.0

        # Build pattern context
        pattern_context = self._build_pattern_context(analysis)

        # Create signal
        signal = GeneratedSignal(
            symbol=symbol,
            signal_timestamp=analysis.timestamp,
            signal_type=signal_type,
            entry_price=entry_price,
            stop_loss=stop_loss,
            target_price=target_price,
            confidence=confidence,
            signal_strength=float(analysis.signal_strength),
            timeframe_alignment=float(analysis.alignment.alignment_score),
            risk_reward_ratio=rr_ratio,
            htf_trend=analysis.htf_trend,
            trading_tf_state=analysis.alignment.trading_tf_state.value,
            confluence_zones_count=len(analysis.confluence_zones),
            pattern_context=pattern_context,
            htf_timeframe=analysis.htf_timeframe,
            trading_timeframe=analysis.trading_timeframe,
        )

        return [signal]

    def generate_tiered_signals(
        self,
        symbol: str,
        htf_data: TimeframeData,
        trading_tf_data: TimeframeData,
        ltf_data: Optional[TimeframeData] = None,
    ) -> List[GeneratedSignal]:
        """
        Generate trading signals using tiered approach.
        
        This method tries to generate signals at different confidence tiers,
        allowing the system to capture medium and low confidence opportunities
        while prioritizing high confidence setups.
        
        The method will return at most one signal, using the highest tier that
        meets its criteria. This prevents duplicate signals for the same opportunity.
        
        Args:
            symbol: Market symbol
            htf_data: Higher timeframe data
            trading_tf_data: Trading timeframe data
            ltf_data: Optional lower timeframe data
            
        Returns:
            List of generated signals (0-1 signal, highest tier that qualifies)
        """
        if self.tiered_config is None:
            # Fall back to standard signal generation
            return self.generate_signals(symbol, htf_data, trading_tf_data, ltf_data)
        
        # Run multi-timeframe analysis once
        analysis = self.coordinator.analyze(htf_data, trading_tf_data, ltf_data)
        
        # Try each tier in priority order (HIGH -> MEDIUM -> LOW)
        for tier in [SignalTier.HIGH, SignalTier.MEDIUM, SignalTier.LOW]:
            if tier not in self.tiered_config.enabled_tiers:
                continue
            
            signal = self._try_generate_signal_for_tier(
                symbol, analysis, trading_tf_data, tier
            )
            
            if signal:
                logger.info(
                    f"{symbol}: Generated {tier.value} tier signal - "
                    f"confidence={signal.confidence:.2f}, "
                    f"position_multiplier={signal.position_size_multiplier:.2f}"
                )
                return [signal]
        
        # No tier met criteria
        return []

    def _try_generate_signal_for_tier(
        self,
        symbol: str,
        analysis: MultiTimeframeAnalysis,
        trading_tf_data: TimeframeData,
        tier: SignalTier,
    ) -> Optional[GeneratedSignal]:
        """
        Try to generate a signal for a specific tier.
        
        Args:
            symbol: Market symbol
            analysis: Multi-timeframe analysis
            trading_tf_data: Trading timeframe data
            tier: Tier to try
            
        Returns:
            GeneratedSignal if tier criteria met, None otherwise
        """
        thresholds = self.tiered_config.get_tier_thresholds(tier)
        
        # Check tier-specific criteria
        if not self._meets_tier_criteria(analysis, thresholds):
            return None
        
        # Determine direction
        direction = self._determine_direction_for_tier(analysis, thresholds)
        if direction is None:
            return None
        
        # Map to signal type
        signal_type = self._map_direction_to_signal(direction, analysis)
        if signal_type is None:
            return None
        
        # Exit signals don't use tiered logic
        if signal_type in (SignalType.EXIT_LONG, SignalType.EXIT_SHORT):
            return None
        
        # Check pattern requirement for tier
        if thresholds.require_pattern:
            if not self._has_supporting_pattern(analysis, direction):
                return None
        
        # Select zone
        zone = self._select_zone_for_tier(analysis, direction, thresholds)
        if zone is None:
            return None
        
        # Calculate levels
        entry_price, stop_loss, target_price = self._calculate_levels(
            signal_type, analysis, trading_tf_data, zone
        )
        
        # Calculate confidence
        confidence = self._calculate_confidence(analysis)
        
        # Calculate risk/reward ratio
        risk = abs(entry_price - stop_loss)
        reward = abs(target_price - entry_price)
        rr_ratio = float(reward / risk) if risk > 0 else 0.0
        
        # Build pattern context
        pattern_context = self._build_pattern_context(analysis)
        pattern_context["tier"] = tier.value
        
        # Create signal with tier info
        signal = GeneratedSignal(
            symbol=symbol,
            signal_timestamp=analysis.timestamp,
            signal_type=signal_type,
            entry_price=entry_price,
            stop_loss=stop_loss,
            target_price=target_price,
            confidence=confidence,
            signal_strength=float(analysis.signal_strength),
            timeframe_alignment=float(analysis.alignment.alignment_score),
            risk_reward_ratio=rr_ratio,
            htf_trend=analysis.htf_trend,
            trading_tf_state=analysis.alignment.trading_tf_state.value,
            confluence_zones_count=len(analysis.confluence_zones),
            pattern_context=pattern_context,
            htf_timeframe=analysis.htf_timeframe,
            trading_timeframe=analysis.trading_timeframe,
            tier=tier,
            position_size_multiplier=thresholds.position_size_multiplier,
        )
        
        return signal

    def _meets_tier_criteria(
        self, 
        analysis: MultiTimeframeAnalysis, 
        thresholds: TierThresholds
    ) -> bool:
        """Check if analysis meets tier-specific criteria."""
        # Check alignment score
        if float(analysis.alignment.alignment_score) < thresholds.min_alignment_score:
            return False
        
        # Check signal strength
        if float(analysis.signal_strength) < thresholds.min_signal_strength:
            return False
        
        # Check trade permitted by HTF
        if not analysis.alignment.trade_permitted:
            return False
        
        # Check zones exist
        if not analysis.confluence_zones:
            return False
        
        return True

    def _determine_direction_for_tier(
        self, 
        analysis: MultiTimeframeAnalysis, 
        thresholds: TierThresholds
    ) -> Optional[TrendDirection]:
        """Determine direction using tier-specific thresholds."""
        if float(analysis.alignment.alignment_score) < thresholds.min_alignment_score:
            return None
        if float(analysis.signal_strength) < thresholds.min_signal_strength:
            return None
        if not analysis.alignment.trade_permitted:
            return None
        
        if analysis.recommended_action == "long" and analysis.htf_trend == TrendDirection.UP:
            return TrendDirection.UP
        if analysis.recommended_action == "short" and analysis.htf_trend == TrendDirection.DOWN:
            return TrendDirection.DOWN
        
        return None

    def _select_zone_for_tier(
        self, 
        analysis: MultiTimeframeAnalysis, 
        direction: TrendDirection,
        thresholds: TierThresholds
    ) -> Optional[ConfluenceZone]:
        """Select confluence zone using tier-specific thresholds."""
        desired_type = "support" if direction == TrendDirection.UP else "resistance"
        for zone in analysis.confluence_zones:
            if zone.zone_type != desired_type:
                continue
            if float(zone.weighted_strength) >= thresholds.min_zone_weight:
                return zone
        return None

    def generate_exit_signals(
        self,
        symbol: str,
        htf_data: TimeframeData,
        trading_tf_data: TimeframeData,
        current_position: SignalType,
        ltf_data: Optional[TimeframeData] = None,
    ) -> List[GeneratedSignal]:
        """
        Generate exit signals based on exhaust patterns or HTF trend reversal.
        
        This method is designed to be called when there is an existing position
        to check if exit conditions are met.
        
        Exit conditions:
        1. Exhaust pattern detected against current position direction
        2. HTF trend reversal against current position
        3. Termination touch at key level against position
        
        Args:
            symbol: Market symbol
            htf_data: Higher timeframe data
            trading_tf_data: Trading timeframe data
            current_position: Current position type (LONG or SHORT)
            ltf_data: Optional lower timeframe data
            
        Returns:
            List of exit signals (typically 0-1)
        """
        if current_position not in (SignalType.LONG, SignalType.SHORT):
            logger.debug(f"{symbol}: Invalid position type for exit signal: {current_position}")
            return []
        
        # Run multi-timeframe analysis
        analysis = self.coordinator.analyze(htf_data, trading_tf_data, ltf_data)
        
        exit_reasons: List[str] = []
        exit_confidence = 0.0
        
        # Check for exhaust patterns against position
        exhaust_exit = self._check_exhaust_exit(analysis, current_position)
        if exhaust_exit:
            exit_reasons.append("exhaust_pattern")
            exit_confidence = max(exit_confidence, 0.7)
        
        # Check for HTF trend reversal against position
        htf_reversal = self._check_htf_trend_reversal(analysis, current_position)
        if htf_reversal:
            exit_reasons.append("htf_trend_reversal")
            exit_confidence = max(exit_confidence, 0.8)
        
        # Check for termination touch against position
        termination_exit = self._check_termination_exit(analysis, current_position)
        if termination_exit:
            exit_reasons.append("termination_touch")
            exit_confidence = max(exit_confidence, 0.65)
        
        # No exit conditions met
        if not exit_reasons:
            return []
        
        # Determine exit signal type
        exit_signal_type = (
            SignalType.EXIT_LONG if current_position == SignalType.LONG 
            else SignalType.EXIT_SHORT
        )
        
        # Get current price for exit
        if not trading_tf_data.pldot_series:
            logger.warning(f"{symbol}: No PLdot data for exit price calculation")
            return []
        
        current_pldot = trading_tf_data.pldot_series[-1]
        exit_price = current_pldot.value
        
        # Build pattern context with exit reasons
        pattern_context = self._build_pattern_context(analysis)
        pattern_context["exit_reasons"] = exit_reasons
        
        # Create exit signal
        signal = GeneratedSignal(
            symbol=symbol,
            signal_timestamp=analysis.timestamp,
            signal_type=exit_signal_type,
            entry_price=exit_price,
            stop_loss=exit_price,  # N/A for exits
            target_price=exit_price,  # N/A for exits
            confidence=exit_confidence,
            signal_strength=float(analysis.signal_strength),
            timeframe_alignment=float(analysis.alignment.alignment_score),
            risk_reward_ratio=0.0,  # N/A for exits
            htf_trend=analysis.htf_trend,
            trading_tf_state=analysis.alignment.trading_tf_state.value,
            confluence_zones_count=len(analysis.confluence_zones),
            pattern_context=pattern_context,
            htf_timeframe=analysis.htf_timeframe,
            trading_timeframe=analysis.trading_timeframe,
        )
        
        logger.info(
            f"{symbol}: Exit signal generated - type={exit_signal_type.value}, "
            f"reasons={exit_reasons}, confidence={exit_confidence:.2f}"
        )
        
        return [signal]

    def _check_exhaust_exit(
        self, 
        analysis: MultiTimeframeAnalysis, 
        current_position: SignalType
    ) -> bool:
        """
        Check if exhaust pattern indicates exit from current position.
        
        For LONG position: bearish exhaust (direction=-1) signals exit
        For SHORT position: bullish exhaust (direction=1) signals exit
        """
        # Determine which exhaust direction would trigger exit
        exit_direction = -1 if current_position == SignalType.LONG else 1
        
        def is_exit_exhaust(event: PatternEvent) -> bool:
            return (
                event.pattern_type == PatternType.EXHAUST
                and event.direction == exit_direction
                and event.strength >= self.required_pattern_strength
            )
        
        # Check both timeframes for exhaust patterns
        return (
            any(is_exit_exhaust(e) for e in analysis.trading_tf_patterns) or
            any(is_exit_exhaust(e) for e in analysis.htf_patterns)
        )

    def _check_htf_trend_reversal(
        self, 
        analysis: MultiTimeframeAnalysis, 
        current_position: SignalType
    ) -> bool:
        """
        Check if HTF trend has reversed against current position.
        
        For LONG position: HTF trend DOWN signals exit
        For SHORT position: HTF trend UP signals exit
        """
        if current_position == SignalType.LONG:
            return analysis.htf_trend == TrendDirection.DOWN
        else:  # SHORT
            return analysis.htf_trend == TrendDirection.UP

    def _check_termination_exit(
        self, 
        analysis: MultiTimeframeAnalysis, 
        current_position: SignalType
    ) -> bool:
        """
        Check if termination touch at key level suggests exit.
        
        For LONG position: termination touch with bearish direction signals exit
        For SHORT position: termination touch with bullish direction signals exit
        """
        # Determine which termination direction would trigger exit
        exit_direction = -1 if current_position == SignalType.LONG else 1
        
        def is_exit_termination(event: PatternEvent) -> bool:
            return (
                event.pattern_type == PatternType.TERMINATION_TOUCH
                and event.direction == exit_direction
                and event.strength >= self.required_pattern_strength
            )
        
        # Check both timeframes for termination patterns
        return (
            any(is_exit_termination(e) for e in analysis.trading_tf_patterns) or
            any(is_exit_termination(e) for e in analysis.htf_patterns)
        )

    def _meets_minimum_criteria(self, analysis: MultiTimeframeAnalysis) -> bool:
        """
        Check if analysis meets minimum criteria for signal generation.

        Args:
            analysis: Multi-timeframe analysis

        Returns:
            True if criteria met
        """
        # Check alignment score
        if float(analysis.alignment.alignment_score) < self.min_alignment_score:
            return False

        # Check signal strength
        if float(analysis.signal_strength) < self.min_signal_strength:
            return False

        # Check that trade is permitted by HTF
        if not analysis.alignment.trade_permitted:
            return False

        if not analysis.confluence_zones:
            return False

        top_zone = analysis.confluence_zones[0]
        if float(top_zone.weighted_strength) < self.min_zone_weight:
            return False

        return True

    def _determine_direction(self, analysis: MultiTimeframeAnalysis) -> Optional[TrendDirection]:
        if float(analysis.alignment.alignment_score) < self.min_alignment_score:
            return None
        if float(analysis.signal_strength) < self.min_signal_strength:
            return None
        if not analysis.alignment.trade_permitted:
            return None

        if analysis.recommended_action == "long" and analysis.htf_trend == TrendDirection.UP:
            return TrendDirection.UP
        if analysis.recommended_action == "short" and analysis.htf_trend == TrendDirection.DOWN:
            return TrendDirection.DOWN

        if analysis.recommended_action in {"reduce", "wait"} or analysis.risk_level == "high":
            if analysis.htf_trend == TrendDirection.UP:
                return TrendDirection.DOWN
            if analysis.htf_trend == TrendDirection.DOWN:
                return TrendDirection.UP
        return None

    def _map_direction_to_signal(
        self, direction: TrendDirection, analysis: MultiTimeframeAnalysis
    ) -> Optional[SignalType]:
        if direction == TrendDirection.UP and analysis.recommended_action == "long":
            return SignalType.LONG
        if direction == TrendDirection.DOWN and analysis.recommended_action == "short":
            return SignalType.SHORT
        if direction == TrendDirection.UP and analysis.recommended_action in {"reduce", "wait"}:
            return SignalType.EXIT_SHORT
        if direction == TrendDirection.DOWN and analysis.recommended_action in {"reduce", "wait"}:
            return SignalType.EXIT_LONG
        return None

    def _select_zone(
        self, analysis: MultiTimeframeAnalysis, direction: TrendDirection
    ) -> Optional[ConfluenceZone]:
        desired_type = "support" if direction == TrendDirection.UP else "resistance"
        for zone in analysis.confluence_zones:
            if zone.zone_type != desired_type:
                continue
            if float(zone.weighted_strength) >= self.min_zone_weight:
                return zone
        return None

    def _has_supporting_pattern(
        self, analysis: MultiTimeframeAnalysis, direction: TrendDirection
    ) -> bool:
        required_direction = 1 if direction == TrendDirection.UP else -1

        def matches(event: PatternEvent) -> bool:
            return (
                event.direction == required_direction
                and event.pattern_type in {
                    PatternType.PLDOT_PUSH,
                    PatternType.C_WAVE,
                    PatternType.PLDOT_REFRESH,
                    PatternType.TERMINATION_TOUCH,  # Price reached projected Drummond line
                }
                and event.strength >= self.required_pattern_strength
            )

        return any(matches(event) for event in analysis.trading_tf_patterns) or any(
            matches(event) for event in analysis.htf_patterns
        )

    def _calculate_levels(
        self,
        signal_type: SignalType,
        analysis: MultiTimeframeAnalysis,
        trading_tf_data: TimeframeData,
        zone: Optional[ConfluenceZone],
    ) -> tuple[Decimal, Decimal, Decimal]:
        """
        Calculate entry, stop loss, and target price levels.

        Logic:
        - Entry: Current PLdot value at trading TF
        - Stop: Entry +/- (ATR * multiplier) based on direction
        - Target: Entry +/- (stop_distance * RR_ratio) based on direction

        For confluence zones: adjust entry to nearest zone level

        Args:
            signal_type: Type of signal
            analysis: Multi-timeframe analysis
            trading_tf_data: Trading timeframe data

        Returns:
            Tuple of (entry_price, stop_loss, target_price)
        """
        # Get current trading TF PLdot as baseline entry
        if not trading_tf_data.pldot_series:
            raise ValueError("No PLdot data available for entry calculation")

        current_pldot = trading_tf_data.pldot_series[-1]
        entry_price = zone.level if zone is not None else current_pldot.value

        buffer = max(zone.volatility, Decimal("0.001") * entry_price) if zone is not None else Decimal("0")
        stop_buffer = buffer * Decimal(str(self.stop_loss_atr_multiplier))

        # Calculate stop and target based on signal direction
        if signal_type == SignalType.LONG and zone is not None:
            stop_loss = zone.lower_bound - stop_buffer
            risk = entry_price - stop_loss
            target_price = entry_price + (risk * Decimal(str(self.target_rr_ratio)))

        elif signal_type == SignalType.SHORT and zone is not None:
            stop_loss = zone.upper_bound + stop_buffer
            risk = stop_loss - entry_price
            target_price = entry_price - (risk * Decimal(str(self.target_rr_ratio)))

        elif signal_type in [SignalType.EXIT_LONG, SignalType.EXIT_SHORT]:
            # For exits, entry is current price, stop/target are N/A but set to entry
            stop_loss = entry_price
            target_price = entry_price

        else:
            raise ValueError(f"Unexpected signal type: {signal_type}")

        return entry_price, stop_loss, target_price

    def _calculate_confidence(self, analysis: MultiTimeframeAnalysis) -> float:
        """
        Calculate signal confidence score (0.0-1.0).

        Factors:
        - Timeframe alignment strength (30%)
        - Pattern confluence (20%)
        - HTF trend strength (25%)
        - Confluence zone count (15%)
        - Signal strength from analysis (10%)

        Args:
            analysis: Multi-timeframe analysis

        Returns:
            Confidence score between 0.0 and 1.0
        """
        # Component scores (0.0-1.0)
        alignment_component = float(analysis.alignment.alignment_score) * 0.30

        pattern_component = 0.20 if analysis.pattern_confluence else 0.10

        htf_strength_component = float(analysis.htf_trend_strength) * 0.25

        # Confluence zones: normalize by max expected (e.g., 5 zones = full score)
        max_zones = 5
        zones_count = min(len(analysis.confluence_zones), max_zones)
        zones_component = (zones_count / max_zones) * 0.15

        signal_strength_component = float(analysis.signal_strength) * 0.10

        # Sum components
        confidence = (
            alignment_component +
            pattern_component +
            htf_strength_component +
            zones_component +
            signal_strength_component
        )

        # Clamp to [0.0, 1.0]
        return max(0.0, min(1.0, confidence))

    def _build_pattern_context(self, analysis: MultiTimeframeAnalysis) -> Dict[str, Any]:
        """
        Build pattern context dictionary for signal metadata.

        Args:
            analysis: Multi-timeframe analysis

        Returns:
            Dictionary with pattern and indicator context
        """
        return {
            "htf_patterns": [
                {
                    "type": p.pattern_type.value,
                    "direction": p.direction,
                    "strength": p.strength,
                }
                for p in analysis.htf_patterns
            ],
            "trading_tf_patterns": [
                {
                    "type": p.pattern_type.value,
                    "direction": p.direction,
                    "strength": p.strength,
                }
                for p in analysis.trading_tf_patterns
            ],
            "alignment_type": analysis.alignment.alignment_type,
            "risk_level": analysis.risk_level,
            "recommended_action": analysis.recommended_action,
            "htf_pldot": float(analysis.pldot_overlay.htf_pldot_value),
            "trading_pldot": float(analysis.pldot_overlay.ltf_pldot_value),
            "pldot_distance_pct": float(analysis.pldot_overlay.distance_percent),
        }


class SignalAggregator:
    """
    Aggregate, filter, and rank signals for notification.

    Responsibilities:
    - Remove duplicate signals (same symbol + direction within time window)
    - Apply user-defined filters (min confidence, enabled patterns, etc.)
    - Rank signals by composite score for priority notification
    """

    def __init__(
        self,
        duplicate_window_minutes: int = 60,
    ):
        """
        Initialize signal aggregator.

        Args:
            duplicate_window_minutes: Time window for duplicate detection
        """
        self.duplicate_window_minutes = duplicate_window_minutes

    def aggregate_signals(
        self,
        signals: List[GeneratedSignal],
        min_confidence: Optional[float] = None,
        min_alignment: Optional[float] = None,
        enabled_patterns: Optional[List[str]] = None,
        max_signals: Optional[int] = None,
    ) -> List[GeneratedSignal]:
        """
        Filter, de-duplicate, and rank signals.

        Args:
            signals: Input signals
            min_confidence: Minimum confidence filter
            min_alignment: Minimum timeframe alignment filter
            enabled_patterns: List of enabled pattern types (None = all)
            max_signals: Maximum signals to return

        Returns:
            Filtered and ranked signals
        """
        if not signals:
            return []

        # Step 1: Apply filters
        filtered = self._apply_filters(
            signals, min_confidence, min_alignment, enabled_patterns
        )

        if not filtered:
            return []

        # Step 2: Remove duplicates
        deduplicated = self._detect_duplicates(filtered)

        # Step 3: Rank by composite score
        ranked = self._rank_signals(deduplicated)

        # Step 4: Limit to max_signals if specified
        if max_signals is not None:
            ranked = ranked[:max_signals]

        return ranked

    def _apply_filters(
        self,
        signals: List[GeneratedSignal],
        min_confidence: Optional[float],
        min_alignment: Optional[float],
        enabled_patterns: Optional[List[str]],
    ) -> List[GeneratedSignal]:
        """Apply user-defined filters to signals."""
        filtered = signals

        # Filter by minimum confidence
        if min_confidence is not None:
            filtered = [s for s in filtered if s.confidence >= min_confidence]

        # Filter by minimum alignment
        if min_alignment is not None:
            filtered = [s for s in filtered if s.timeframe_alignment >= min_alignment]

        # Filter by enabled patterns
        if enabled_patterns is not None:
            # Check if signal has any of the enabled patterns
            filtered = [
                s for s in filtered
                if self._has_enabled_pattern(s, enabled_patterns)
            ]

        return filtered

    def _has_enabled_pattern(
        self, signal: GeneratedSignal, enabled_patterns: List[str]
    ) -> bool:
        """Check if signal contains any enabled patterns."""
        signal_patterns = []

        # Extract pattern types from context
        if "htf_patterns" in signal.pattern_context:
            signal_patterns.extend([p["type"] for p in signal.pattern_context["htf_patterns"]])
        if "trading_tf_patterns" in signal.pattern_context:
            signal_patterns.extend([p["type"] for p in signal.pattern_context["trading_tf_patterns"]])

        # Check if any signal pattern is in enabled list
        return any(p in enabled_patterns for p in signal_patterns) if signal_patterns else True

    def _detect_duplicates(
        self, signals: List[GeneratedSignal]
    ) -> List[GeneratedSignal]:
        """
        Remove duplicate signals for same symbol + signal type within time window.

        Keep the signal with highest confidence.
        """
        if len(signals) <= 1:
            return signals

        # Group by (symbol, signal_type)
        groups: Dict[tuple[str, SignalType], List[GeneratedSignal]] = {}
        for signal in signals:
            key = (signal.symbol, signal.signal_type)
            if key not in groups:
                groups[key] = []
            groups[key].append(signal)

        # For each group, keep only highest confidence signal within time window
        deduplicated = []
        for group_signals in groups.values():
            if len(group_signals) == 1:
                deduplicated.append(group_signals[0])
            else:
                # Sort by timestamp
                sorted_signals = sorted(group_signals, key=lambda s: s.signal_timestamp)

                # Keep non-overlapping signals
                kept = [sorted_signals[0]]
                for signal in sorted_signals[1:]:
                    last_kept = kept[-1]
                    time_diff_minutes = (
                        signal.signal_timestamp - last_kept.signal_timestamp
                    ).total_seconds() / 60

                    if time_diff_minutes > self.duplicate_window_minutes:
                        # Outside window, keep both
                        kept.append(signal)
                    else:
                        # Within window, keep higher confidence
                        if signal.confidence > last_kept.confidence:
                            kept[-1] = signal

                deduplicated.extend(kept)

        return deduplicated

    def _rank_signals(self, signals: List[GeneratedSignal]) -> List[GeneratedSignal]:
        """
        Rank signals by composite score.

        Score = confidence * signal_strength * timeframe_alignment
        """
        def composite_score(signal: GeneratedSignal) -> float:
            return signal.confidence * signal.signal_strength * signal.timeframe_alignment

        return sorted(signals, key=composite_score, reverse=True)


@dataclass(frozen=True)
class PredictionRunResult:
    """Result of a single prediction cycle execution."""
    run_id: int
    timestamp: datetime
    symbols_requested: int
    symbols_processed: int
    signals_generated: int
    execution_time_ms: int
    errors: List[str]
    status: str  # "SUCCESS", "PARTIAL", "FAILED"

    # Latency breakdown
    data_fetch_ms: Optional[int] = None
    indicator_calc_ms: Optional[int] = None
    signal_generation_ms: Optional[int] = None

    # Generated signals (for notification)
    signals: List[GeneratedSignal] = field(default_factory=list)


class PredictionEngine:
    """
    Orchestrate the full prediction pipeline.

    This class coordinates:
    1. Incremental data refresh from EODHD
    2. Indicator recalculation for updated symbols
    3. Multi-timeframe signal generation
    4. Result persistence

    Usage:
        engine = PredictionEngine(settings, persistence)
        result = engine.execute_prediction_cycle(
            symbols=["AAPL", "MSFT"],
            interval="30min",
            timeframes=["4h", "1h", "30min"]
        )
    """

    def __init__(
        self,
        settings: Any = None,  # Will import Settings type
        persistence: Any = None,  # Will import PredictionPersistence type
        signal_generator: Optional[SignalGenerator] = None,
        lookback_bars: int = 200,
    ):
        """
        Initialize prediction engine.

        Args:
            settings: Settings instance (imported from dgas.settings)
            persistence: PredictionPersistence instance
            signal_generator: Optional SignalGenerator (will create default if None)
            lookback_bars: Number of bars to load for analysis
        """
        if settings is None:
            from ..settings import get_settings
            settings = get_settings()

        if persistence is None:
            from ..prediction.persistence import PredictionPersistence
            persistence = PredictionPersistence(settings)

        self.settings = settings
        self.persistence = persistence
        self.lookback_bars = lookback_bars

        # Create default signal generator if not provided
        if signal_generator is None:
            from ..calculations.multi_timeframe import MultiTimeframeCoordinator
            coordinator = MultiTimeframeCoordinator(
                htf_timeframe="4h",
                trading_timeframe="1h",
            )
            signal_generator = SignalGenerator(coordinator)

        self.signal_generator = signal_generator

    def execute_prediction_cycle(
        self,
        symbols: List[str],
        interval: str,
        timeframes: List[str],
        htf_interval: Optional[str] = None,
        trading_interval: Optional[str] = None,
        persist_results: bool = True,
    ) -> PredictionRunResult:
        """
        Execute full prediction cycle for given symbols.

        Steps:
        1. Refresh market data (incremental update)
        2. Recalculate indicators for symbols with new data
        3. Generate signals via SignalGenerator
        4. Persist signals and run metadata
        5. Return execution results

        Args:
            symbols: List of symbols to analyze
            interval: Primary interval for analysis
            timeframes: List of timeframes for multi-TF analysis
            htf_interval: Optional override for higher timeframe (default: timeframes[0])
            trading_interval: Optional override for trading timeframe (default: timeframes[1] or interval)
            persist_results: Whether to save to database

        Returns:
            PredictionRunResult with execution metadata
        """
        import time
        from datetime import timezone

        start_time = time.time()
        run_timestamp = datetime.now(timezone.utc)
        errors = []
        symbols_processed = 0
        all_signals = []

        # Determine timeframes
        if htf_interval is None:
            htf_interval = timeframes[0] if len(timeframes) > 0 else "4h"
        if trading_interval is None:
            trading_interval = timeframes[1] if len(timeframes) > 1 else interval

        # Step 1: Check data freshness (data collection service handles updates)
        # Note: Data refresh is now handled by the separate data collection service
        # We only verify freshness here to warn if data is stale
        data_fetch_start = time.time()
        stale_symbols = self._check_data_freshness(symbols, interval, max_age_minutes=15)
        data_fetch_ms = int((time.time() - data_fetch_start) * 1000)
        
        if stale_symbols:
            logger.warning(
                f"Stale data detected: {len(stale_symbols)} symbols have data older than 15 minutes. "
                f"Data collection service should update data. Sample: {stale_symbols[:5]}"
            )
            # Add warnings to errors list
            for symbol, age_minutes in stale_symbols[:10]:
                errors.append(f"{symbol}: Data age {age_minutes:.1f} minutes (may be stale)")

        # Step 2: Recalculate indicators and generate signals
        indicator_calc_start = time.time()
        signal_gen_start = None
        signal_gen_ms = 0

        for symbol in symbols:
            try:
                # Load market data
                intervals_data = self._load_market_data(symbol, interval)
                if not intervals_data:
                    errors.append(f"{symbol}: No market data available")
                    continue

                # Calculate indicators for all required timeframes
                htf_data = None
                trading_data = None

                # Load HTF data if different from primary interval
                if htf_interval != interval:
                    try:
                        htf_intervals = self._load_market_data(symbol, htf_interval)
                        if htf_intervals:
                            htf_data = self._calculate_timeframe_data(
                                htf_intervals, htf_interval, TimeframeType.HIGHER
                            )
                    except Exception as e:
                        errors.append(f"{symbol}: HTF data error - {str(e)}")

                # Load trading TF data
                if trading_interval == interval:
                    trading_data = self._calculate_timeframe_data(
                        intervals_data, trading_interval, TimeframeType.TRADING
                    )
                else:
                    try:
                        trading_intervals = self._load_market_data(symbol, trading_interval)
                        if trading_intervals:
                            trading_data = self._calculate_timeframe_data(
                                trading_intervals, trading_interval, TimeframeType.TRADING
                            )
                    except Exception as e:
                        errors.append(f"{symbol}: Trading TF data error - {str(e)}")

                # Ensure we have both HTF and trading data
                if htf_data is None or trading_data is None:
                    errors.append(f"{symbol}: Missing timeframe data")
                    continue

                # Step 3: Generate signals
                if signal_gen_start is None:
                    signal_gen_start = time.time()

                signals = self.signal_generator.generate_signals(
                    symbol, htf_data, trading_data
                )
                all_signals.extend(signals)
                symbols_processed += 1

            except Exception as e:
                errors.append(f"{symbol}: {str(e)}")

        indicator_calc_ms = int((time.time() - indicator_calc_start) * 1000)
        if signal_gen_start:
            signal_gen_ms = int((time.time() - signal_gen_start) * 1000)

        # Calculate total execution time
        execution_time_ms = int((time.time() - start_time) * 1000)

        # Determine status
        if symbols_processed == 0:
            status = "FAILED"
        elif symbols_processed < len(symbols):
            status = "PARTIAL"
        else:
            status = "SUCCESS"

        # Step 4: Persist results if requested
        run_id = 0
        if persist_results:
            try:
                # Save prediction run
                run_id = self.persistence.save_prediction_run(
                    interval_type=interval,
                    symbols_requested=len(symbols),
                    symbols_processed=symbols_processed,
                    signals_generated=len(all_signals),
                    execution_time_ms=execution_time_ms,
                    status=status,
                    data_fetch_ms=data_fetch_ms,
                    indicator_calc_ms=indicator_calc_ms,
                    signal_generation_ms=signal_gen_ms,
                    errors=errors if errors else None,
                    run_timestamp=run_timestamp,
                )

                # Save generated signals
                if all_signals:
                    signal_dicts = [self._signal_to_dict(s) for s in all_signals]
                    self.persistence.save_generated_signals(run_id, signal_dicts)

            except Exception as e:
                errors.append(f"Persistence error: {str(e)}")
                status = "FAILED"

        # Return result with signals
        return PredictionRunResult(
            run_id=run_id,
            timestamp=run_timestamp,
            symbols_requested=len(symbols),
            symbols_processed=symbols_processed,
            signals_generated=len(all_signals),
            execution_time_ms=execution_time_ms,
            errors=errors,
            status=status,
            data_fetch_ms=data_fetch_ms,
            indicator_calc_ms=indicator_calc_ms,
            signal_generation_ms=signal_gen_ms,
            signals=all_signals,  # Include signal objects for notification
        )

    def _refresh_market_data(
        self,
        symbols: List[str],
        interval: str,
        errors: List[str],
    ) -> List[str]:
        """
        Incrementally refresh market data for symbols.

        Args:
            symbols: Symbols to update
            interval: Interval to update
            errors: List to append errors to

        Returns:
            List of symbols that were successfully updated
        """
        from ..data.ingestion import incremental_update_intraday
        import logging
        logger = logging.getLogger(__name__)

        logger.info(f"Refreshing market data for {len(symbols)} symbols (interval: {interval})")
        updated = []
        total_fetched = 0
        total_stored = 0
        
        for symbol in symbols:
            try:
                # Perform incremental update (fetches only recent data)
                summary = incremental_update_intraday(
                    symbol,
                    exchange="US",  # Default exchange
                    interval=interval,
                    buffer_days=2,  # 2 days buffer
                )

                total_fetched += summary.fetched
                total_stored += summary.stored

                if summary.stored > 0:
                    updated.append(symbol)
                    logger.debug(f"{symbol}: Fetched {summary.fetched} bars, stored {summary.stored} new bars")
                elif summary.fetched > 0:
                    logger.debug(f"{symbol}: Fetched {summary.fetched} bars, 0 new (already up to date)")

            except Exception as e:
                error_msg = f"{symbol}: Data refresh failed - {str(e)}"
                errors.append(error_msg)
                logger.warning(error_msg)

        logger.info(f"Data refresh complete: {len(updated)}/{len(symbols)} symbols updated, "
                    f"{total_fetched} bars fetched, {total_stored} new bars stored")
        return updated

    def _check_data_freshness(
        self,
        symbols: List[str],
        interval: str,
        max_age_minutes: int = 15,
    ) -> List[tuple[str, float]]:
        """
        Check data freshness for symbols.
        
        Returns list of (symbol, age_minutes) tuples for symbols with stale data.
        
        Args:
            symbols: Symbols to check
            interval: Data interval
            max_age_minutes: Maximum age in minutes before considered stale
            
        Returns:
            List of (symbol, age_minutes) tuples for stale symbols
        """
        from datetime import datetime, timezone
        from ..data.repository import get_latest_timestamp, ensure_market_symbol
        from ..db import get_connection
        
        stale_symbols: List[tuple[str, float]] = []
        now = datetime.now(timezone.utc)
        
        with get_connection() as conn:
            for symbol in symbols:
                try:
                    symbol_id = ensure_market_symbol(conn, symbol, "US")
                    latest_ts = get_latest_timestamp(conn, symbol_id, interval)
                    
                    if latest_ts:
                        age_minutes = (now - latest_ts).total_seconds() / 60.0
                        if age_minutes > max_age_minutes:
                            stale_symbols.append((symbol, age_minutes))
                    else:
                        # No data - consider stale
                        stale_symbols.append((symbol, float("inf")))
                except Exception as e:
                    logger.debug(f"Error checking freshness for {symbol}: {e}")
                    # Don't add to stale list on error, just log
        
        return stale_symbols

    def _load_market_data(
        self,
        symbol: str,
        interval: str,
    ) -> List[IntervalData]:
        """
        Load market data from database.

        Args:
            symbol: Symbol to load
            interval: Interval to load

        Returns:
            List of IntervalData in chronological order
        """
        from ..db import get_connection
        from ..data.repository import (
            fetch_market_data_with_aggregation,
            get_symbol_id,
        )

        with get_connection() as conn:
            symbol_id = get_symbol_id(conn, symbol)
            if symbol_id is None:
                raise ValueError(f"Symbol {symbol} not found in database")

            data = fetch_market_data_with_aggregation(
                conn,
                symbol,
                interval,
                limit=self.lookback_bars,
            )

        return data

    def _calculate_timeframe_data(
        self,
        intervals: List[IntervalData],
        timeframe: str,
        classification: Any,  # TimeframeType
    ) -> TimeframeData:
        """
        Calculate all Drummond indicators for a timeframe.

        Args:
            intervals: Market data intervals
            timeframe: Timeframe label (e.g., "4h", "1h")
            classification: TimeframeType classification

        Returns:
            TimeframeData with all indicators calculated
        """
        return build_timeframe_data(intervals, timeframe, classification)

    def _signal_to_dict(self, signal: GeneratedSignal) -> Dict[str, Any]:
        """
        Convert GeneratedSignal to dictionary for persistence.

        Args:
            signal: Generated signal

        Returns:
            Dictionary compatible with save_generated_signals
        """
        return {
            "symbol": signal.symbol,
            "signal_timestamp": signal.signal_timestamp,
            "signal_type": signal.signal_type.value,
            "entry_price": signal.entry_price,
            "stop_loss": signal.stop_loss,
            "target_price": signal.target_price,
            "confidence": signal.confidence,
            "signal_strength": signal.signal_strength,
            "timeframe_alignment": signal.timeframe_alignment,
            "risk_reward_ratio": signal.risk_reward_ratio,
            "htf_trend": signal.htf_trend.value,
            "trading_tf_state": signal.trading_tf_state,
            "confluence_zones_count": signal.confluence_zones_count,
            "pattern_context": signal.pattern_context,
            "notification_sent": signal.notification_sent,
            "notification_channels": signal.notification_channels,
            "notification_timestamp": signal.notification_timestamp,
        }


__all__ = [
    "SignalType",
    "GeneratedSignal",
    "SignalGenerator",
    "SignalAggregator",
    "PredictionEngine",
    "PredictionRunResult",
]
